{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/capGoblin/Transformer-from-Scratch-Text_Summarizer/blob/main/Transformer_from_Scratch_for_Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2019 The TensorFlow Authors.\n",
        "\n",
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T15:22:12.919884Z",
          "iopub.execute_input": "2023-07-12T15:22:12.920293Z",
          "iopub.status.idle": "2023-07-12T15:22:12.925892Z",
          "shell.execute_reply.started": "2023-07-12T15:22:12.920244Z",
          "shell.execute_reply": "2023-07-12T15:22:12.924657Z"
        },
        "trusted": true,
        "id": "zC2rFTCQqhss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifications Copyright (C) 2020 Rohan Jagtap"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T15:22:12.931657Z",
          "iopub.execute_input": "2023-07-12T15:22:12.932356Z",
          "iopub.status.idle": "2023-07-12T15:22:12.939898Z",
          "shell.execute_reply.started": "2023-07-12T15:22:12.932314Z",
          "shell.execute_reply": "2023-07-12T15:22:12.939123Z"
        },
        "trusted": true,
        "id": "FOEn6ZM1qhsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content/drive/My Drive/Colab Notebooks/summarizer_transformer/"
      ],
      "metadata": {
        "id": "ImPCIsrTE5sF",
        "execution": {
          "iopub.status.busy": "2023-07-12T15:22:12.942503Z",
          "iopub.execute_input": "2023-07-12T15:22:12.943353Z",
          "iopub.status.idle": "2023-07-12T15:22:12.952901Z",
          "shell.execute_reply.started": "2023-07-12T15:22:12.943298Z",
          "shell.execute_reply": "2023-07-12T15:22:12.951875Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW2vM63xqpjF",
        "outputId": "8cb3c995-126c-42d4-c56e-4fb1d0449a8b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "BymxhVa7rEzy",
        "outputId": "61d50b78-e285-454f-eecf-32367e56ee36"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-41cb8ae0-a224-4954-b0eb-ca43ef6d218a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-41cb8ae0-a224-4954-b0eb-ca43ef6d218a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-72edf3658aa1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    157\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    158\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "CE-xt4TBrE8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2267988b-1a7f-47a3-a3ad-3577583592c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "sCcgB2HirKwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4d519b-65d9-4a3e-8aa9-867fecd29350"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d shashichander009/inshorts-news-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n77uBcgkrMV5",
        "outputId": "ed61f2a2-2837-4809-a8af-016d3964c54e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/shashichander009/inshorts-news-data\n",
            "License(s): unknown\n",
            "Downloading inshorts-news-data.zip to /content\n",
            " 40% 5.00M/12.6M [00:00<00:00, 21.1MB/s]\n",
            "100% 12.6M/12.6M [00:00<00:00, 44.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/inshorts-news-data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXREPFsuBPfS",
        "outputId": "720ea731-44d7-42b0-dd95-eda475b2a74f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/inshorts-news-data.zip\n",
            "  inflating: Inshorts Cleaned Data.xlsx  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, LayerNormalization, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.train import Checkpoint, CheckpointManager\n",
        "from tensorflow.keras.metrics import Mean"
      ],
      "metadata": {
        "id": "Zbxhyl_zFlWL",
        "execution": {
          "iopub.status.busy": "2023-07-12T15:22:12.954829Z",
          "iopub.execute_input": "2023-07-12T15:22:12.955268Z",
          "iopub.status.idle": "2023-07-12T15:22:21.691466Z",
          "shell.execute_reply.started": "2023-07-12T15:22:12.955227Z",
          "shell.execute_reply": "2023-07-12T15:22:21.690200Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Data"
      ],
      "metadata": {
        "id": "yH5cg5pSIHaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/Inshorts Cleaned Data.xlsx', sheet_name='Sheet1', usecols=[0,1])"
      ],
      "metadata": {
        "id": "K_AjGkWXITKA",
        "execution": {
          "iopub.status.busy": "2023-07-12T15:22:21.693308Z",
          "iopub.execute_input": "2023-07-12T15:22:21.694108Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "S-rYZhayIe9x",
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oXtxc-toIc94",
        "outputId": "ddd8dc27-5207-401c-fb73-c2d69c26cec5",
        "trusted": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Headline  \\\n",
              "0  4 ex-bank officials booked for cheating bank o...   \n",
              "1     Supreme Court to go paperless in 6 months: CJI   \n",
              "2  At least 3 killed, 30 injured in blast in Sylh...   \n",
              "3  Why has Reliance been barred from trading in f...   \n",
              "4  Was stopped from entering my own studio at Tim...   \n",
              "\n",
              "                                               Short  \n",
              "0  The CBI on Saturday booked four former officia...  \n",
              "1  Chief Justice JS Khehar has said the Supreme C...  \n",
              "2  At least three people were killed, including a...  \n",
              "3  Mukesh Ambani-led Reliance Industries (RIL) wa...  \n",
              "4  TV news anchor Arnab Goswami has said he was t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8051b06e-df82-4583-9771-00387a8e8a70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Short</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
              "      <td>The CBI on Saturday booked four former officia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
              "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
              "      <td>At least three people were killed, including a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why has Reliance been barred from trading in f...</td>\n",
              "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Was stopped from entering my own studio at Tim...</td>\n",
              "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8051b06e-df82-4583-9771-00387a8e8a70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8051b06e-df82-4583-9771-00387a8e8a70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8051b06e-df82-4583-9771-00387a8e8a70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e41bf0e-863d-4e3f-9b2d-a5ad55ce7cae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e41bf0e-863d-4e3f-9b2d-a5ad55ce7cae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e41bf0e-863d-4e3f-9b2d-a5ad55ce7cae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 55104,\n  \"fields\": [\n    {\n      \"column\": \"Headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 54940,\n        \"samples\": [\n          \"Happy to be back with Salman for Tiger Zinda Hai: Kaif\",\n          \" Lawsuit claims Oculus Co-founder spread fake origin story\",\n          \"Gambhir only Indian to make 100s in 5 straight Tests\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Short\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 54997,\n        \"samples\": [\n          \"An Australian couple who own a tropical island resort in Micronesia has decided to give it away in lottery rather than sell it to the highest bidder. The lottery kicked off in April, and so far 55,500 people from 150 countries have bought tickets which start from $49. The lottery for the 16-bed resort will be drawn on Tuesday.\",\n          \"Over 200 rail accidents out of 292, from 2012-13 to January 2016, were caused due to the failure of railway staff as per the data of the Railway Ministry. The data suggested that action was being taken against 542 employees for their negligence and penalties were imposed in over 500 cases based on investigations by Commission of Railway Safety (CRS).\",\n          \"A 1400-km long optical fibre cable has been built connecting the two most precise optical atomic clocks in Europe, located in Germany and France. This marks the first and most accurate comparison of atomic clocks across national borders, a feat that may allow time-sensitive scientific experiments like observing changes in the values of fundamental physical constants over time.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR2hg9themaN",
        "outputId": "be9749f3-8846-4d8f-fb38-8442cb9892cf",
        "trusted": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55104, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news = data['Short']\n",
        "summary = data['Headline']"
      ],
      "metadata": {
        "id": "d4cEp3wmI2BX",
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news[30], summary[30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z55AhpKIdK7",
        "outputId": "a75e9780-3711-4613-dafb-f74ec54a0334",
        "trusted": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('According to the Guinness World Records, the most generations alive in a single family have been seven.  The difference between the oldest and the youngest person in the family was about 109 years, when Augusta Bunge&#39;s great-great-great-great grandson was born on January 21, 1989. The family belonged to the United States of America.',\n",
              " 'The most generations alive in a single family have been 7')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "f8gKyq1gIq4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for decoder sequence\n",
        "# summary = summary.apply(lambda x: '<START> ' + x + ' <END>')\n",
        "# summary.head()\n",
        "\n",
        "\n",
        "def add_tokens(x):\n",
        "    return '<START> ' + x + ' <END>'\n",
        "\n",
        "summary = summary.apply(add_tokens)\n",
        "print(\"Summary after adding tokens:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ6LE4MrJjC_",
        "outputId": "3aaa5458-cb80-44bd-dde5-9ce21e88e575",
        "trusted": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary after adding tokens:\n",
            "0        <START> 4 ex-bank officials booked for cheatin...\n",
            "1        <START> Supreme Court to go paperless in 6 mon...\n",
            "2        <START> At least 3 killed, 30 injured in blast...\n",
            "3        <START> Why has Reliance been barred from trad...\n",
            "4        <START> Was stopped from entering my own studi...\n",
            "                               ...                        \n",
            "55099    <START> Sensex loses 400 points to hit 52-week...\n",
            "55100    <START> China to inject $91 bn into the money ...\n",
            "55101    <START> Ghulam Ali set to make acting debut in...\n",
            "55102    <START> IS acknowledges death of Jihadi John: ...\n",
            "55103    <START> Cairn to seek $600 mn from India in da...\n",
            "Name: Headline, Length: 55104, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizing the texts into integer tokens"
      ],
      "metadata": {
        "id": "95Zv7FIvKbTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since < and > from default tokens cannot be removed\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'\n",
        "\n",
        "news_tokenizer = Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = Tokenizer(filters=filters, oov_token=oov_token)\n",
        "\n",
        "news_tokenizer.fit_on_texts(news)\n",
        "summary_tokenizer.fit_on_texts(summary)\n",
        "\n",
        "inputs = news_tokenizer.texts_to_sequences(news)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "metadata": {
        "id": "7TqbpEyPMRqa",
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.texts_to_sequences([\"my mother is doctor\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVyErXAei5_b",
        "outputId": "db2150eb-8070-4a4f-c18c-8c07f99de531",
        "trusted": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[111, 579, 22, 1533]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.sequences_to_texts([[579, 232, 123, 871]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryx9qx90jwXu",
        "outputId": "ee5ac9ab-1257-4cb2-a588-9aac8127a642",
        "trusted": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mother 16 hc review']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_vocab_size = len(news_tokenizer.word_index) + 1\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "# vocab_size\n",
        "encoder_vocab_size, decoder_vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoizyBvLKv8h",
        "outputId": "1fa0cc06-30df-457d-9ef7-c7e7a2bc3735",
        "trusted": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76362, 29661)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Obtaining insights on lengths for defining maxlen"
      ],
      "metadata": {
        "id": "mZden_q9_eZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_lengths = []\n",
        "summary_lengths = []\n",
        "\n",
        "for n,s in zip(news, summary):\n",
        "    news_lengths.append(len(n))\n",
        "    summary_lengths.append(len(s))\n",
        "\n",
        "\n",
        "\n",
        "news_lengths = pd.Series(news_lengths)\n",
        "summary_lengths = pd.Series(summary_lengths)\n"
      ],
      "metadata": {
        "id": "ma4o2nGdK5Xb",
        "trusted": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_lengths.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXZlO99C-UXK",
        "outputId": "d156312d-5317-4f65-95e7-f1b8534d60d7",
        "trusted": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean       368.003049\n",
              "std         26.235510\n",
              "min        280.000000\n",
              "25%        350.000000\n",
              "50%        369.000000\n",
              "75%        387.000000\n",
              "max        469.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_lengths.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALMwKMx--ZF7",
        "outputId": "b33f95fe-664f-4504-e0fd-e3d7c5d40359",
        "trusted": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean        65.620282\n",
              "std          7.267463\n",
              "min         22.000000\n",
              "25%         61.000000\n",
              "50%         65.000000\n",
              "75%         71.000000\n",
              "max         98.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# maxlen\n",
        "# taking values > and round figured to 75th percentile\n",
        "# at the same time not leaving high variance\n",
        "encoder_maxlen = 400\n",
        "decoder_maxlen = 75"
      ],
      "metadata": {
        "id": "cVeMilXr-bpC",
        "trusted": true
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Padding/Truncating sequences for identical sequence lengths"
      ],
      "metadata": {
        "id": "_SWap3YJBk-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "targets = pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "vEyUBeu7ACRt",
        "trusted": true
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating ds pipeline"
      ],
      "metadata": {
        "id": "wIP0kIIcB8Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.cast(inputs, dtype=tf.int32)\n",
        "targets = tf.cast(targets, dtype=tf.int32)"
      ],
      "metadata": {
        "id": "LzO6l3-AB7hJ",
        "trusted": true
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "slZ5f4P4DurS",
        "trusted": true
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "wI-fV7eABWN6",
        "trusted": true
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for inputs , targets in enumerate(ds):\n",
        "    print(inputs)\n",
        "    print(targets)\n",
        "    count+=1\n",
        "\n",
        "    if count > 2:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BIbubkLeZOf",
        "outputId": "ad2facf8-8db1-444e-b82b-09a74f7f4158"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "(<tf.Tensor: shape=(64, 400), dtype=int32, numpy=\n",
            "array([[ 343,   52,    5, ...,    0,    0,    0],\n",
            "       [ 564, 1408,  341, ...,    0,    0,    0],\n",
            "       [  31,    4,   11, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2, 6352,    6, ...,    0,    0,    0],\n",
            "       [5035, 3329,   15, ...,    0,    0,    0],\n",
            "       [ 833, 1044, 1437, ...,    0,    0,    0]], dtype=int32)>, <tf.Tensor: shape=(64, 75), dtype=int32, numpy=\n",
            "array([[   2,  369,  202, ...,    0,    0,    0],\n",
            "       [   2,  381,  101, ...,    0,    0,    0],\n",
            "       [   2,  602, 4229, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2, 3718,    9, ...,    0,    0,    0],\n",
            "       [   2, 3342, 1782, ...,    0,    0,    0],\n",
            "       [   2,   49,  524, ...,    0,    0,    0]], dtype=int32)>)\n",
            "1\n",
            "(<tf.Tensor: shape=(64, 400), dtype=int32, numpy=\n",
            "array([[3759,  110, 2643, ...,    0,    0,    0],\n",
            "       [ 972, 1029,   16, ...,    0,    0,    0],\n",
            "       [  50, 1078,  372, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 904,    8,    2, ...,    0,    0,    0],\n",
            "       [   7,  285,   38, ...,    0,    0,    0],\n",
            "       [ 374,  481,    9, ...,    0,    0,    0]], dtype=int32)>, <tf.Tensor: shape=(64, 75), dtype=int32, numpy=\n",
            "array([[   2,  222,  524, ...,    0,    0,    0],\n",
            "       [   2,  939,   22, ...,    0,    0,    0],\n",
            "       [   2,   37,    4, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2,  442, 1750, ...,    0,    0,    0],\n",
            "       [   2,   96, 3549, ...,    0,    0,    0],\n",
            "       [   2,  499,  716, ...,    0,    0,    0]], dtype=int32)>)\n",
            "2\n",
            "(<tf.Tensor: shape=(64, 400), dtype=int32, numpy=\n",
            "array([[  114,  1687, 11339, ...,     0,     0,     0],\n",
            "       [    2,  3187,     5, ...,     0,     0,     0],\n",
            "       [ 4757,   109,    50, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  580,    77,  3744, ...,     0,     0,     0],\n",
            "       [  833,   717,  3110, ...,     0,     0,     0],\n",
            "       [   50,   149,     4, ...,     0,     0,     0]], dtype=int32)>, <tf.Tensor: shape=(64, 75), dtype=int32, numpy=\n",
            "array([[   2,   48,  586, ...,    0,    0,    0],\n",
            "       [   2, 3185,    6, ...,    0,    0,    0],\n",
            "       [   2,    6, 6221, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2, 4031,   80, ...,    0,    0,    0],\n",
            "       [   2, 3013, 2016, ...,    0,    0,    0],\n",
            "       [   2,   11,   70, ...,    0,    0,    0]], dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset created:\")\n",
        "print(\"Number of batches in the dataset:\", tf.data.experimental.cardinality(ds))\n",
        "print(\"Batch size:\", BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgWDliiTedJS",
        "outputId": "1cf053c5-2b06-4dc0-c273-9b339e46750a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created:\n",
            "Number of batches in the dataset: tf.Tensor(861, shape=(), dtype=int64)\n",
            "Batch size: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Encoding for adding notion of position among words as unlike RNN this is non-directional"
      ],
      "metadata": {
        "id": "isN1CpAXLfsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates"
      ],
      "metadata": {
        "id": "Purv7oyhETDZ",
        "trusted": true
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    position = np.arange(position)[:, np.newaxis]\n",
        "    i = np.arange(d_model)[np.newaxis, :]\n",
        "\n",
        "    exponent = (2 * (i // 2)) / np.float32(d_model)\n",
        "#     print(exponent.shape)\n",
        "    # Create angle values for each position and dimension\n",
        "    angle_rates = 1 / np.power(10000, exponent)\n",
        "#     print(angle_rates.shape)\n",
        "    # Compute the angle values for the positions\n",
        "    angle_rads = position * angle_rates\n",
        "#     print(angle_rads.shape)\n",
        "    # Apply sine to even indices\n",
        "    angle_rads[:, ::2] = np.sin(angle_rads[:, ::2])\n",
        "\n",
        "    # Apply cosine to odd indices\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "#     print(angle_rads.shape)\n",
        "    # Add an extra dimension to the array\n",
        "    pos_encoding = np.expand_dims(angle_rads, axis=0)\n",
        "#     print(pos_encoding.shape)\n",
        "\n",
        "    # Convert to TensorFlow float32 data type\n",
        "    pos_encoding = tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    return pos_encoding"
      ],
      "metadata": {
        "id": "40J2pc2NEXp5",
        "trusted": true
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking\n",
        "\n",
        "- Padding mask for masking \"pad\" sequences\n",
        "- Lookahead mask for masking future words from contributing in prediction of current words in self attention"
      ],
      "metadata": {
        "id": "24Pe01DMMWHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq):\n",
        "    padding_mask = tf.math.equal(seq, 0)\n",
        "    padding_mask = tf.cast(padding_mask, tf.float32)\n",
        "\n",
        "    padding_mask = tf.expand_dims(padding_mask, axis=1)\n",
        "    padding_mask = tf.expand_dims(padding_mask, axis=2)\n",
        "    return padding_mask\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    ones = tf.ones((size, size))\n",
        "\n",
        "    req_matrix = tf.linalg.band_part(ones, -1, 0)\n",
        "    toggle_req_matrix = 1 - req_matrix\n",
        "    mask = toggle_req_matrix\n",
        "    return mask"
      ],
      "metadata": {
        "id": "Q2RXbjg76FL4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the Model"
      ],
      "metadata": {
        "id": "n8DqUBc4NFOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scaled Dot Product"
      ],
      "metadata": {
        "id": "WfknVF7hNKf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled += (mask * -1e9)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled, axis=-1)\n",
        "\n",
        "    values = tf.matmul(attention_weights, v)\n",
        "    return values, attention_weights"
      ],
      "metadata": {
        "id": "w_B6M9OBNBKB",
        "trusted": true
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-Headed Attention"
      ],
      "metadata": {
        "id": "Rf7_a5uQOfJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.head_dim = d_model // self.num_heads\n",
        "\n",
        "        self.wq = Dense(d_model)\n",
        "        self.wk = Dense(d_model)\n",
        "        self.wv = Dense(d_model)\n",
        "\n",
        "        self.linear_dense = Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.head_dim))\n",
        "\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, q, k, v, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        values, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "\n",
        "        values = tf.transpose(values, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_values = tf.reshape(values, (batch_size, -1, self.d_model))\n",
        "\n",
        "        output = self.linear_dense(concat_values)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "id": "iIuFrdXnNZEC",
        "trusted": true
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feed Forward Network"
      ],
      "metadata": {
        "id": "A49tXMVvOkOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, hidden):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(hidden, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "metadata": {
        "id": "d9-qoKuTNwKq",
        "trusted": true
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PointwiseFeedForward(Layer):\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PointwiseFeedForward, self).__init__()\n",
        "        self.linear1 = Dense(hidden, activation='relu')\n",
        "        self.linear2 = Dense(d_model)\n",
        "        self.dropout = Dropout(rate=drop_prob)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cDUolDfP66vK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fundamental Unit of Transformer encoder"
      ],
      "metadata": {
        "id": "B2RRmn2bOpW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(Layer):\n",
        "    def __init__(self, d_model, num_heads, hidden, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate=rate)\n",
        "\n",
        "        self.ffn = PointwiseFeedForward(d_model, hidden, drop_prob=rate)\n",
        "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout2 = Dropout(rate=rate)\n",
        "\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        residual_x = tf.identity(x)\n",
        "        x, _ = self.attention(x, x, x, mask)\n",
        "        x = self.dropout1(x, training=training)\n",
        "        x = self.norm1(residual_x + x)\n",
        "        residual_x = tf.identity(x)\n",
        "\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout2(x, training=training)\n",
        "        x = self.norm2(residual_x + x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "HNuoJoFWO335",
        "trusted": true
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fundamental Unit of Transformer decoder"
      ],
      "metadata": {
        "id": "9i6Zh8gnPqdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(Layer):\n",
        "    def __init__(self, d_model, num_heads, hidden, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.attention1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.attention2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        # self.ffn = point_wise_feed_forward_network(d_model, hidden)\n",
        "        self.ffn = PointwiseFeedForward(d_model, hidden, drop_prob=rate)\n",
        "\n",
        "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.norm3 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = Dropout(rate=rate)\n",
        "        self.dropout2 = Dropout(rate=rate)\n",
        "        self.dropout3 = Dropout(rate=rate)\n",
        "\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        output1, attention_weights1 = self.attention1(x, x, x, look_ahead_mask)\n",
        "        output1 = self.dropout1(output1, training=training)\n",
        "        output1 = self.norm1(output1 + x)\n",
        "\n",
        "        output2, attention_weights2 = self.attention2(output1, enc_output, enc_output,  padding_mask)\n",
        "        output2 = self.dropout2(output2, training=training)\n",
        "        output2 = self.norm2(output2 + output1)\n",
        "\n",
        "        output3 = self.ffn(output2)\n",
        "        output3 = self.dropout3(output3, training=training)\n",
        "        output3 = self.norm3(output3 + output2)\n",
        "\n",
        "        return output3, attention_weights1, attention_weights2\n"
      ],
      "metadata": {
        "id": "7CVmvs6dPMRC",
        "trusted": true
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder consisting of multiple EncoderLayer(s)"
      ],
      "metadata": {
        "id": "6zt5MUc_QNid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Layer):\n",
        "    def __init__(self,  d_model, num_layers, num_heads, hidden, input_vocab_size, max_pos_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(max_pos_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, hidden, rate) for _ in range(num_layers)]\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "BrbnTwijQJ-h",
        "trusted": true
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder consisting of multiple DecoderLayer(s)"
      ],
      "metadata": {
        "id": "4N5LrNrvRexg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Layer):\n",
        "    def __init__(self, d_model, num_layers,  num_heads, hidden, target_vocab_size, max_pos_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(max_pos_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, hidden, rate) for _ in range(num_layers)]\n",
        "        self.dropout = Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        return x, attention_weights\n"
      ],
      "metadata": {
        "id": "UmeqkZrIRbSB",
        "trusted": true
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finally, the Transformer"
      ],
      "metadata": {
        "id": "lbMNK_bzSHnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(Model):\n",
        "    def __init__(self, d_model, num_layers, num_heads, hidden, input_vocab_size, target_vocab_size, max_pos_input, max_pos_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(d_model, num_layers, num_heads, hidden, input_vocab_size, max_pos_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(d_model, num_layers, num_heads, hidden, target_vocab_size, max_pos_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights\n"
      ],
      "metadata": {
        "id": "FXHRG-o4R9Mc",
        "trusted": true
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "UndsMPZXTdSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-params\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "hidden = 512\n",
        "num_heads = 8\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "lMTZJdIoSbuy",
        "trusted": true
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adam optimizer with custom learning rate scheduling"
      ],
      "metadata": {
        "id": "uOGvkYDNTjIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(LearningRateSchedule):  # Using the Adam optimizer with a custom learning rate scheduler according to the formula in the original Transformer paper.\n",
        "    def __init__(self, d_model, warmup_steps=4000): # lrate = d_model^-0.5 * min(step_num^-0.5, step_num * warmup_steps^-1.5)\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, dtype=tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step* (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ],
      "metadata": {
        "id": "tfiynCLlTL8C",
        "trusted": true
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining losses and other metrics"
      ],
      "metadata": {
        "id": "DsVdrENTUERY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "Ip1-943kTXXK",
        "trusted": true
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ],
      "metadata": {
        "id": "ktKwyvKtTvF6",
        "trusted": true
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n"
      ],
      "metadata": {
        "id": "uW4LA_45T4Aa",
        "trusted": true
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')"
      ],
      "metadata": {
        "id": "Ze0u6xxXT7dI",
        "trusted": true
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformer"
      ],
      "metadata": {
        "id": "9XvKy3v6ULnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(\n",
        "    d_model,\n",
        "    num_layers,\n",
        "    num_heads,\n",
        "    hidden,\n",
        "    encoder_vocab_size,\n",
        "    decoder_vocab_size,\n",
        "    max_pos_input=encoder_vocab_size,\n",
        "    max_pos_target=decoder_vocab_size,\n",
        ")"
      ],
      "metadata": {
        "id": "d5-RcxqFUCuk",
        "trusted": true
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Masks"
      ],
      "metadata": {
        "id": "f56BGiVXU_Dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(inputs, targets):\n",
        "    enc_padding_mask = create_padding_mask(inputs)\n",
        "    dec_padding_mask = create_padding_mask(inputs)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(targets)[1])\n",
        "\n",
        "    dec_target_padding_mask = create_padding_mask(targets)\n",
        "\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "metadata": {
        "id": "FZxHuyZxU5Pa",
        "trusted": true
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checkpoints"
      ],
      "metadata": {
        "id": "SYIotvaBVI0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"checkpoints\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print('Latest checkpoint restored!')\n"
      ],
      "metadata": {
        "id": "tOc1_3c-VGaL",
        "trusted": true
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training steps"
      ],
      "metadata": {
        "id": "WfpI0gS4c06c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp,\n",
        "            True,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)"
      ],
      "metadata": {
        "id": "xmVOMzkrczgl",
        "trusted": true
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    count = 0\n",
        "    for (batch, (inp, tar)) in enumerate(ds):\n",
        "        train_step(inp, tar)\n",
        "        if batch % 429 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "\n",
        "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
        "\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2J5R8m6qhtL",
        "outputId": "32aa34d9-b602-4638-bf8b-83df53e15e9e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 10.3062\n",
            "Epoch 1 Batch 429 Loss 9.2045\n",
            "Epoch 1 Batch 858 Loss 8.2501\n",
            "Epoch 1 Loss 8.2474\n",
            "Time taken for 1 epoch: 366.69614124298096 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 7.3107\n",
            "Epoch 2 Batch 429 Loss 6.7867\n",
            "Epoch 2 Batch 858 Loss 6.5922\n",
            "Epoch 2 Loss 6.5915\n",
            "Time taken for 1 epoch: 331.55168652534485 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 6.1761\n",
            "Epoch 3 Batch 429 Loss 6.0822\n",
            "Epoch 3 Batch 858 Loss 5.9370\n",
            "Epoch 3 Loss 5.9367\n",
            "Time taken for 1 epoch: 331.43073439598083 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 5.7241\n",
            "Epoch 4 Batch 429 Loss 5.5346\n",
            "Epoch 4 Batch 858 Loss 5.4080\n",
            "Epoch 4 Loss 5.4074\n",
            "Time taken for 1 epoch: 331.237966299057 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 5.2034\n",
            "Epoch 5 Batch 429 Loss 5.0724\n",
            "Epoch 5 Batch 858 Loss 4.9895\n",
            "Saving checkpoint for epoch 5 at checkpoints/ckpt-1\n",
            "Epoch 5 Loss 4.9894\n",
            "Time taken for 1 epoch: 332.67554545402527 secs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "PVbEUCZagJ0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predicting one word at a time at the decoder and appending it to the output; then taking the complete sequence as an input to the decoder and repeating until maxlen or stop keyword appears"
      ],
      "metadata": {
        "id": "YMbqGTixu1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(input_news):\n",
        "    input_news = news_tokenizer.texts_to_sequences([input_news])\n",
        "    input_news = tf.keras.preprocessing.sequence.pad_sequences(input_news, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_news[0], 0)\n",
        "\n",
        "    decoder_input = [summary_tokenizer.word_index['<start>']]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "    for i in range(decoder_maxlen):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input,\n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == summary_tokenizer.word_index['<end>']:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights\n"
      ],
      "metadata": {
        "id": "F5D5cv2Jd8-6",
        "trusted": true
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(input_news):\n",
        "    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
        "    summarized = evaluate(input_news=input_news)[0].numpy()\n",
        "    summarized = np.expand_dims(summarized[1:], 0)  # not printing <START> token\n",
        "    return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated news"
      ],
      "metadata": {
        "id": "UkpdiW6wnmiS",
        "trusted": true
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkinbulk(randomnumber):\n",
        "  print('Actual summary:', summarize(news[randomnumber]))\n",
        "  print('News: ', news[randomnumber])\n",
        "  print('Actual summary: ', summary[randomnumber][7:-6])\n",
        "\n"
      ],
      "metadata": {
        "id": "Azfs-rvlTfOd"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_number = random.randint(0, 55104)\n",
        "checkinbulk(random_number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_FUA-pqTfP6",
        "outputId": "dd360224-a7a2-4428-8503-b17a48139ab1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual summary: sa team takes 10 000 test test team in test team\n",
            "News:  South Africa became the fourth visiting team, after England, West Indies, and India, to dismiss Australia below 100 after bowling them out for 85 in the ongoing Hobart Test. While England has dismissed Australia at home below 100 runs nine times, the most by any visiting team, it was for the first time that South Africa achieved the feat.\n",
            "Actual summary:   Australia have been dismissed below 100 by 4 visiting teams\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(\n",
        "    \"A historic achievement has been made in the realm of space exploration. Astronomers have detected the presence of an Earth-like planet orbiting a distant star within the habitable zone. This exciting discovery raises the possibility of finding extraterrestrial life and provides valuable insights into the existence of other habitable worlds beyond our own. Scientists are now planning detailed observations and future missions to explore this intriguing exoplanet further. The discovery marks a significant milestone in our quest to unravel the mysteries of the universe and understand our place in the cosmos\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WZoEHvIxrYKZ",
        "outputId": "21884cd2-ee85-45f2-f1e2-7b66ac1455e1",
        "trusted": true
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'astronomers discover star of earth 39 s atmosphere'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfg4SoaFYmUa",
        "outputId": "9575cf29-f880-49f7-af2c-ccde0e7a61f1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  10567424  \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  4854912   \n",
            "                                                                 \n",
            " dense_64 (Dense)            multiple                  3826269   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19248605 (73.43 MB)\n",
            "Trainable params: 19248605 (73.43 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}