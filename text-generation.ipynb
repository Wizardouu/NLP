{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-03T10:41:57.794128Z",
     "iopub.status.busy": "2024-07-03T10:41:57.793875Z",
     "iopub.status.idle": "2024-07-03T10:41:57.817612Z",
     "shell.execute_reply": "2024-07-03T10:41:57.816911Z",
     "shell.execute_reply.started": "2024-07-03T10:41:57.794076Z"
    },
    "id": "a4a114b9",
    "papermill": {
     "duration": 4.480734,
     "end_time": "2021-09-30T17:41:37.185324",
     "exception": false,
     "start_time": "2021-09-30T17:41:32.704590",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-03T10:41:57.819286Z",
     "iopub.status.busy": "2024-07-03T10:41:57.818996Z",
     "iopub.status.idle": "2024-07-03T10:42:00.451918Z",
     "shell.execute_reply": "2024-07-03T10:42:00.451080Z",
     "shell.execute_reply.started": "2024-07-03T10:41:57.819232Z"
    },
    "id": "5896a2f8",
    "outputId": "2598af11-6a37-485a-b359-37a4a7bdfe27",
    "papermill": {
     "duration": 0.072018,
     "end_time": "2021-09-30T17:41:37.299206",
     "exception": false,
     "start_time": "2021-09-30T17:41:37.227188",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24248"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def read_file_to_sentences(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n",
    "all_headlines = read_file_to_sentences(\"/kaggle/input/corpus2/game_of_thrones.txt\")\n",
    "len(all_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-03T10:42:09.566760Z",
     "iopub.status.busy": "2024-07-03T10:42:09.566469Z",
     "iopub.status.idle": "2024-07-03T10:42:09.572111Z",
     "shell.execute_reply": "2024-07-03T10:42:09.571433Z",
     "shell.execute_reply.started": "2024-07-03T10:42:09.566715Z"
    },
    "id": "86a8ddd4",
    "outputId": "447561ee-056c-489a-ce95-0fb7ff4d32ec",
    "papermill": {
     "duration": 0.026046,
     "end_time": "2021-09-30T17:41:37.341958",
     "exception": false,
     "start_time": "2021-09-30T17:41:37.315912",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Song of Ice and Fire\\n\\nA Game of Thrones\\n\\nPROLOGUE\\n\\nWe should start back, Gared urged as the woods began to grow dark around them.',\n",
       " 'The wildlings are dead.',\n",
       " 'Do the dead frighten you?',\n",
       " 'Ser Waymar Royce asked with just the hint of a smile.',\n",
       " 'Gared did not rise to the bait.',\n",
       " 'He was an old man, past fifty, and he had seen the lordlings come and go.',\n",
       " 'Dead is dead, he said.',\n",
       " 'We have no business with the dead.',\n",
       " 'Are they dead?',\n",
       " 'Royce asked softly.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_headlines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b8bf84ed-da11-4f89-a584-9dceea677420",
    "_uuid": "2a07365a27a7ba2f92fc9ba4d05d8e6254a68d8c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-03T10:42:12.100212Z",
     "iopub.status.busy": "2024-07-03T10:42:12.099934Z",
     "iopub.status.idle": "2024-07-03T10:42:12.442976Z",
     "shell.execute_reply": "2024-07-03T10:42:12.442259Z",
     "shell.execute_reply.started": "2024-07-03T10:42:12.100171Z"
    },
    "id": "273f39b8",
    "outputId": "ce85ef69-c5bc-4c8c-e06b-f54b5887b4a9",
    "papermill": {
     "duration": 0.034873,
     "end_time": "2021-09-30T17:41:37.424319",
     "exception": false,
     "start_time": "2021-09-30T17:41:37.389446",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a song of ice and fire\\n\\na game of thrones\\n\\nprologue\\n\\nwe should start back gared urged as the woods began to grow dark around them',\n",
       " 'the wildlings are dead',\n",
       " 'do the dead frighten you',\n",
       " 'ser waymar royce asked with just the hint of a smile',\n",
       " 'gared did not rise to the bait',\n",
       " 'he was an old man past fifty and he had seen the lordlings come and go',\n",
       " 'dead is dead he said',\n",
       " 'we have no business with the dead',\n",
       " 'are they dead',\n",
       " 'royce asked softly']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt\n",
    "\n",
    "corpus = [clean_text(x) for x in all_headlines]\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-03T10:42:15.280285Z",
     "iopub.status.busy": "2024-07-03T10:42:15.280007Z",
     "iopub.status.idle": "2024-07-03T10:42:15.869935Z",
     "shell.execute_reply": "2024-07-03T10:42:15.869172Z",
     "shell.execute_reply.started": "2024-07-03T10:42:15.280244Z"
    },
    "id": "8ddba2e7",
    "outputId": "f10775a7-1140-4c8f-a6f4-6ea8c5bed7b0",
    "papermill": {
     "duration": 0.048788,
     "end_time": "2021-09-30T17:41:37.517111",
     "exception": false,
     "start_time": "2021-09-30T17:41:37.468323",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 187, 2292, 3, 77, 10, 83, 831]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "token_list = tokenizer.texts_to_sequences([\"I am happy to see you here today\"])[0]\n",
    "print(token_list)\n",
    "\n",
    "check=[]\n",
    "\n",
    "for i in range(1, len(token_list)):\n",
    "  n_gram_sequence = token_list[:i+1]\n",
    "  check.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "896543c9-7944-4748-b8ef-ef8cbc2a84f0",
    "_uuid": "9129a8b773feb72eff91aa0025157a173d10c625",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-03T10:42:17.900337Z",
     "iopub.status.busy": "2024-07-03T10:42:17.900045Z",
     "iopub.status.idle": "2024-07-03T10:42:19.497961Z",
     "shell.execute_reply": "2024-07-03T10:42:19.497125Z",
     "shell.execute_reply.started": "2024-07-03T10:42:17.900294Z"
    },
    "id": "e34ee397",
    "outputId": "4e7d2a5d-61db-425d-f61d-210cda43314d",
    "papermill": {
     "duration": 0.063827,
     "end_time": "2021-09-30T17:41:37.596199",
     "exception": false,
     "start_time": "2021-09-30T17:41:37.532372",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[4, 1031],\n",
       "  [4, 1031, 5],\n",
       "  [4, 1031, 5, 553],\n",
       "  [4, 1031, 5, 553, 2],\n",
       "  [4, 1031, 5, 553, 2, 256],\n",
       "  [4, 1031, 5, 553, 2, 256, 4],\n",
       "  [4, 1031, 5, 553, 2, 256, 4, 1293],\n",
       "  [4, 1031, 5, 553, 2, 256, 4, 1293, 5],\n",
       "  [4, 1031, 5, 553, 2, 256, 4, 1293, 5, 2085],\n",
       "  [4, 1031, 5, 553, 2, 256, 4, 1293, 5, 2085, 7573]],\n",
       " 12116)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "    ## convert data to sequence of tokens\n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
    "\n",
    "inp_sequences[:10], total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "73254551-40bd-45b1-a7a5-88fe4cbe0b20",
    "_uuid": "ca588b414e70e21bebcead960f6632805d37dd8c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-03T10:42:24.199441Z",
     "iopub.status.busy": "2024-07-03T10:42:24.199144Z",
     "iopub.status.idle": "2024-07-03T10:42:26.975325Z",
     "shell.execute_reply": "2024-07-03T10:42:26.974499Z",
     "shell.execute_reply.started": "2024-07-03T10:42:24.199396Z"
    },
    "id": "716b957a",
    "outputId": "592eb578-edae-4559-9c12-f40daf8b957a",
    "papermill": {
     "duration": 0.096386,
     "end_time": "2021-09-30T17:41:37.737572",
     "exception": false,
     "start_time": "2021-09-30T17:41:37.641186",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0,    0,    0, ...,    0,    0,    4],\n",
       "        [   0,    0,    0, ...,    0,    4, 1031],\n",
       "        [   0,    0,    0, ...,    4, 1031,    5],\n",
       "        ...,\n",
       "        [   0,    0,    0, ...,   10,   11,    7],\n",
       "        [   0,    0,    0, ...,   11,    7, 1382],\n",
       "        [   0,    0,    0, ...,    7, 1382, 1026]], dtype=int32),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 12116,\n",
       " 131)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
    "predictors,label,len(label[0]),max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "60d6721e-e40e-4f2b-8f63-c06459d68f26",
    "_uuid": "76ef6d9352002d333a7c75e8aed7ce996015f527",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-03T10:48:46.502989Z",
     "iopub.status.busy": "2024-07-03T10:48:46.502690Z",
     "iopub.status.idle": "2024-07-03T10:48:59.293357Z",
     "shell.execute_reply": "2024-07-03T10:48:59.292681Z",
     "shell.execute_reply.started": "2024-07-03T10:48:46.502946Z"
    },
    "id": "dc83c566",
    "outputId": "271692f9-8ea1-401f-c74a-764f3aae50a5",
    "papermill": {
     "duration": 2.114226,
     "end_time": "2021-09-30T17:41:39.898971",
     "exception": false,
     "start_time": "2021-09-30T17:41:37.784745",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors shape: torch.Size([1000, 49]), Labels shape: torch.Size([1000])\n",
      "Predictors device: cpu, Labels device: cpu\n",
      "Epoch 1/100, Loss: 9.2294\n",
      "Epoch 2/100, Loss: 7.9520\n",
      "Epoch 3/100, Loss: 7.0736\n",
      "Epoch 4/100, Loss: 6.5865\n",
      "Epoch 5/100, Loss: 6.1579\n",
      "Epoch 6/100, Loss: 5.6549\n",
      "Epoch 7/100, Loss: 5.0389\n",
      "Epoch 8/100, Loss: 4.3272\n",
      "Epoch 9/100, Loss: 3.5775\n",
      "Epoch 10/100, Loss: 2.8011\n",
      "Epoch 11/100, Loss: 2.0762\n",
      "Epoch 12/100, Loss: 1.4474\n",
      "Epoch 13/100, Loss: 0.9579\n",
      "Epoch 14/100, Loss: 0.6314\n",
      "Epoch 15/100, Loss: 0.4311\n",
      "Epoch 16/100, Loss: 0.3157\n",
      "Epoch 17/100, Loss: 0.2334\n",
      "Epoch 18/100, Loss: 0.1845\n",
      "Epoch 19/100, Loss: 0.1508\n",
      "Epoch 20/100, Loss: 0.1265\n",
      "Epoch 21/100, Loss: 0.1079\n",
      "Epoch 22/100, Loss: 0.0921\n",
      "Epoch 23/100, Loss: 0.0818\n",
      "Epoch 24/100, Loss: 0.0743\n",
      "Epoch 25/100, Loss: 0.0635\n",
      "Epoch 26/100, Loss: 0.0591\n",
      "Epoch 27/100, Loss: 0.0538\n",
      "Epoch 28/100, Loss: 0.0492\n",
      "Epoch 29/100, Loss: 0.0449\n",
      "Epoch 30/100, Loss: 0.0409\n",
      "Epoch 31/100, Loss: 0.0372\n",
      "Epoch 32/100, Loss: 0.0353\n",
      "Epoch 33/100, Loss: 0.0325\n",
      "Epoch 34/100, Loss: 0.0314\n",
      "Epoch 35/100, Loss: 0.0291\n",
      "Epoch 36/100, Loss: 0.0280\n",
      "Epoch 37/100, Loss: 0.0260\n",
      "Epoch 38/100, Loss: 0.0239\n",
      "Epoch 39/100, Loss: 0.0233\n",
      "Epoch 40/100, Loss: 0.0218\n",
      "Epoch 41/100, Loss: 0.0203\n",
      "Epoch 42/100, Loss: 0.0190\n",
      "Epoch 43/100, Loss: 0.0186\n",
      "Epoch 44/100, Loss: 0.0178\n",
      "Epoch 45/100, Loss: 0.0170\n",
      "Epoch 46/100, Loss: 0.0161\n",
      "Epoch 47/100, Loss: 0.0151\n",
      "Epoch 48/100, Loss: 0.0146\n",
      "Epoch 49/100, Loss: 0.0141\n",
      "Epoch 50/100, Loss: 0.0133\n",
      "Epoch 51/100, Loss: 0.0128\n",
      "Epoch 52/100, Loss: 0.0126\n",
      "Epoch 53/100, Loss: 0.0120\n",
      "Epoch 54/100, Loss: 0.0116\n",
      "Epoch 55/100, Loss: 0.0112\n",
      "Epoch 56/100, Loss: 0.0107\n",
      "Epoch 57/100, Loss: 0.0101\n",
      "Epoch 58/100, Loss: 0.0098\n",
      "Epoch 59/100, Loss: 0.0095\n",
      "Epoch 60/100, Loss: 0.0091\n",
      "Epoch 61/100, Loss: 0.0088\n",
      "Epoch 62/100, Loss: 0.0087\n",
      "Epoch 63/100, Loss: 0.0082\n",
      "Epoch 64/100, Loss: 0.0081\n",
      "Epoch 65/100, Loss: 0.0079\n",
      "Epoch 66/100, Loss: 0.0076\n",
      "Epoch 67/100, Loss: 0.0073\n",
      "Epoch 68/100, Loss: 0.0072\n",
      "Epoch 69/100, Loss: 0.0068\n",
      "Epoch 70/100, Loss: 0.0066\n",
      "Epoch 71/100, Loss: 0.0064\n",
      "Epoch 72/100, Loss: 0.0062\n",
      "Epoch 73/100, Loss: 0.0060\n",
      "Epoch 74/100, Loss: 0.0059\n",
      "Epoch 75/100, Loss: 0.0057\n",
      "Epoch 76/100, Loss: 0.0056\n",
      "Epoch 77/100, Loss: 0.0054\n",
      "Epoch 78/100, Loss: 0.0052\n",
      "Epoch 79/100, Loss: 0.0051\n",
      "Epoch 80/100, Loss: 0.0050\n",
      "Epoch 81/100, Loss: 0.0048\n",
      "Epoch 82/100, Loss: 0.0047\n",
      "Epoch 83/100, Loss: 0.0046\n",
      "Epoch 84/100, Loss: 0.0044\n",
      "Epoch 85/100, Loss: 0.0043\n",
      "Epoch 86/100, Loss: 0.0042\n",
      "Epoch 87/100, Loss: 0.0042\n",
      "Epoch 88/100, Loss: 0.0041\n",
      "Epoch 89/100, Loss: 0.0040\n",
      "Epoch 90/100, Loss: 0.0038\n",
      "Epoch 91/100, Loss: 0.0037\n",
      "Epoch 92/100, Loss: 0.0037\n",
      "Epoch 93/100, Loss: 0.0035\n",
      "Epoch 94/100, Loss: 0.0036\n",
      "Epoch 95/100, Loss: 0.0034\n",
      "Epoch 96/100, Loss: 0.0033\n",
      "Epoch 97/100, Loss: 0.0032\n",
      "Epoch 98/100, Loss: 0.0032\n",
      "Epoch 99/100, Loss: 0.0031\n",
      "Epoch 100/100, Loss: 0.0030\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Define the dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, predictors, labels):\n",
    "        self.predictors = predictors\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.predictors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.predictors[idx], self.labels[idx]\n",
    "\n",
    "# Define the model class\n",
    "class TextGenerationModel(nn.Module):\n",
    "    def __init__(self, total_words, embedding_dim, rnn_units):\n",
    "        super(TextGenerationModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(total_words, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, rnn_units, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(rnn_units, total_words)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.dropout(x[:, -1, :])  # Only take the output from the last time step\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, dataset, epochs, batch_size, learning_rate, patience, device):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=patience, min_lr=1e-5)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(dataloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "\n",
    "            # Flatten the output and target for the loss function\n",
    "            output = output.view(-1, output.size(-1))\n",
    "            target = target.view(-1)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_epoch_loss:.4f}')\n",
    "        scheduler.step(avg_epoch_loss)\n",
    "\n",
    "# Parameters\n",
    "total_words = 10000  # Example value; use the actual value from your data\n",
    "embedding_dim = 32\n",
    "rnn_units = 200\n",
    "max_sequence_len = 50  # Example value; use the actual value from your data\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "patience = 5\n",
    "\n",
    "# Example data (replace with actual data)\n",
    "predictors = np.random.randint(0, total_words, (1000, max_sequence_len-1))  # Dummy data\n",
    "labels = np.random.randint(0, total_words, 1000)  # Dummy data\n",
    "\n",
    "# Convert data to tensors\n",
    "predictors = torch.tensor(predictors, dtype=torch.long)\n",
    "labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Check tensor shapes and device\n",
    "print(f\"Predictors shape: {predictors.shape}, Labels shape: {labels.shape}\")\n",
    "print(f\"Predictors device: {predictors.device}, Labels device: {labels.device}\")\n",
    "\n",
    "# Prepare dataset\n",
    "dataset = TextDataset(predictors, labels)\n",
    "\n",
    "# Initialize and train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TextGenerationModel(total_words, embedding_dim, rnn_units).to(device)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataset, epochs, batch_size, learning_rate, patience, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1826aa1a-cb77-4379-a69d-e9b180945dce",
    "_uuid": "f0b16b471969dbb831cb0024e303341e11b63de4",
    "id": "b2113e33",
    "papermill": {
     "duration": 0.015837,
     "end_time": "2021-09-30T17:41:39.931660",
     "exception": false,
     "start_time": "2021-09-30T17:41:39.915823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Lets train our model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "07d5cf03-d171-4993-9f8b-18446649ecb0",
    "_uuid": "156f3303b8120cc6932e6db985cbea4a7ceb08bf",
    "execution": {
     "iopub.execute_input": "2024-07-03T10:25:11.883071Z",
     "iopub.status.busy": "2024-07-03T10:25:11.882795Z"
    },
    "id": "261be263",
    "papermill": {
     "duration": 756.537974,
     "end_time": "2021-09-30T17:54:16.485662",
     "exception": false,
     "start_time": "2021-09-30T17:41:39.947688",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "260626/260626 [==============================] - 532s 2ms/step - loss: 6.5739\n",
      "Epoch 2/8\n",
      "205536/260626 [======================>.......] - ETA: 1:53 - loss: 5.9637"
     ]
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "e71e56543b7065f115a05e3fd062262b3b94ad46",
    "execution": {
     "iopub.execute_input": "2024-07-03T10:58:21.409585Z",
     "iopub.status.busy": "2024-07-03T10:58:21.409245Z",
     "iopub.status.idle": "2024-07-03T10:58:21.419941Z",
     "shell.execute_reply": "2024-07-03T10:58:21.418967Z",
     "shell.execute_reply.started": "2024-07-03T10:58:21.409518Z"
    },
    "id": "ea25320f",
    "papermill": {
     "duration": 3.507383,
     "end_time": "2021-09-30T17:54:30.746176",
     "exception": false,
     "start_time": "2021-09-30T17:54:27.238793",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def generate_text(seed_text, next_words, model, tokenizer, max_sequence_len, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        token_list = torch.tensor(token_list, dtype=torch.long).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predicted_probs = model(token_list)\n",
    "        \n",
    "        predicted = torch.argmax(predicted_probs, dim=-1).item()  # Get the index of the highest probability\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text.title()\n",
    "\n",
    "# Ensure the model, tokenizer, and device are already defined\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "e38dd280-093b-4091-b82b-9aa90045b107",
    "_kg_hide-input": true,
    "_uuid": "a21548224c9e661a29e3d369e348aada0599bdc9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-03T11:02:44.420625Z",
     "iopub.status.busy": "2024-07-03T11:02:44.420335Z",
     "iopub.status.idle": "2024-07-03T11:02:44.486951Z",
     "shell.execute_reply": "2024-07-03T11:02:44.486154Z",
     "shell.execute_reply.started": "2024-07-03T11:02:44.420582Z"
    },
    "id": "6fb05b0b",
    "outputId": "196598e0-5c4e-4665-805f-4e40ef79b59f",
    "papermill": {
     "duration": 4.617206,
     "end_time": "2021-09-30T17:54:46.708976",
     "exception": false,
     "start_time": "2021-09-30T17:54:42.091770",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have  Fiery Bends Sneaking Eighth Favored\n",
      "Did Magister Mornings Humpbacked Stalking Debt\n",
      "We Glistened Bends Startledand Shields Hallooed Claws\n",
      " All The Bodies Favored Outrange Obey\n",
      "Especially Tale List Tide Impressive\n",
      "The Young Knight Partner Fashioned Helplessly Lemon Reward Notched\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"Have \", 5, model, tokenizer, max_sequence_len, device))\n",
    "print(generate_text(\"Did\", 5, model, tokenizer, max_sequence_len, device))\n",
    "print(generate_text(\"We\", 6, model, tokenizer, max_sequence_len, device))\n",
    "print(generate_text(\" All the bodies\", 3, model, tokenizer, max_sequence_len, device))\n",
    "print(generate_text(\"Especially\", 4, model, tokenizer, max_sequence_len, device))\n",
    "print(generate_text(\"The young knight\", 6, model, tokenizer, max_sequence_len, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T11:06:04.103788Z",
     "iopub.status.busy": "2024-07-03T11:06:04.103512Z",
     "iopub.status.idle": "2024-07-03T11:06:04.118537Z",
     "shell.execute_reply": "2024-07-03T11:06:04.117686Z",
     "shell.execute_reply.started": "2024-07-03T11:06:04.103746Z"
    },
    "id": "ZLthwZpX9vNd",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nobody Will Feel Lolling Outside Silverpale Leffords\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"Nobody will feel\", 4, model, tokenizer, max_sequence_len, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 76821,
     "sourceId": 172291,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5326086,
     "sourceId": 8848616,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 12836,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 814.688051,
   "end_time": "2021-09-30T17:55:00.964263",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-30T17:41:26.276212",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
