{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ThweAW0bDJ0T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the data\n",
        "vocab_size = 5000\n",
        "max_words = 400\n",
        "embedding_dim = 32\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_words)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_words)\n",
        "\n",
        "x_valid, y_valid = x_train[:64], y_train[:64]\n",
        "x_train_, y_train_ = x_train[64:], y_train[64:]\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "x_train_ = torch.tensor(x_train_, dtype=torch.long)\n",
        "y_train_ = torch.tensor(y_train_, dtype=torch.float32)\n",
        "x_test = torch.tensor(x_test, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "x_valid = torch.tensor(x_valid, dtype=torch.long)\n",
        "y_valid = torch.tensor(y_valid, dtype=torch.float32)\n",
        "\n",
        "train_data = TensorDataset(x_train_, y_train_)\n",
        "test_data = TensorDataset(x_test, y_test)\n",
        "valid_data = TensorDataset(x_valid, y_valid)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "valid_loader = DataLoader(valid_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "5BccBj0iDOSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d94c11-977a-4d17-83c9-053e10e155a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the PyTorch model\n",
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = x[:, -1, :]  # take the last output of the LSTM\n",
        "        x = self.fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FqNCZTWTDXW7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = BiLSTMModel(vocab_size, embedding_dim, hidden_dim, output_dim).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, Validation Loss: {valid_loss / len(valid_loader)}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        predicted = (outputs.squeeze() > 0.5).float()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct / total * 100:.2f}%')"
      ],
      "metadata": {
        "id": "y-SCdOvRDeJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4a1949-e2be-44eb-8e6f-7d1ee5835731"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Validation Loss: 0.5844866037368774\n",
            "Epoch 2, Validation Loss: 0.5991145372390747\n",
            "Epoch 3, Validation Loss: 0.3796665072441101\n",
            "Epoch 4, Validation Loss: 0.28886598348617554\n",
            "Epoch 5, Validation Loss: 0.5035485625267029\n",
            "Epoch 6, Validation Loss: 0.3269736170768738\n",
            "Epoch 7, Validation Loss: 0.292816162109375\n",
            "Epoch 8, Validation Loss: 0.2389085441827774\n",
            "Epoch 9, Validation Loss: 0.198494091629982\n",
            "Epoch 10, Validation Loss: 0.21582314372062683\n",
            "Accuracy: 83.97%\n"
          ]
        }
      ]
    }
  ]
}