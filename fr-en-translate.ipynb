{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7e7adcb85f194da1b1aa232646e65f6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce687ee043144a93ad6ad052417f5174","IPY_MODEL_7f7c3fea5eb04e2ebf73dc4b79f171cb","IPY_MODEL_c47eec9d3a11419c88337a1eb85ba5ec"],"layout":"IPY_MODEL_401be88ff55d4f79b35431f6ca01b616"}},"ce687ee043144a93ad6ad052417f5174":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38526434c5ad4945af165cfe762e5f2f","placeholder":"​","style":"IPY_MODEL_f590c18cfc6e43be9c2407e2134955d2","value":"Resolving data files: 100%"}},"7f7c3fea5eb04e2ebf73dc4b79f171cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_23d3ff826a8b4ecc952db67be01a6abf","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64ebdadacfcc489e95df535499dd8018","value":30}},"c47eec9d3a11419c88337a1eb85ba5ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_620ffe61b4bb4069954aa771ac0afd8d","placeholder":"​","style":"IPY_MODEL_b54c2335b5584a76a3bbb95fac1a0554","value":" 30/30 [00:00&lt;00:00, 28.95it/s]"}},"401be88ff55d4f79b35431f6ca01b616":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38526434c5ad4945af165cfe762e5f2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f590c18cfc6e43be9c2407e2134955d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23d3ff826a8b4ecc952db67be01a6abf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64ebdadacfcc489e95df535499dd8018":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"620ffe61b4bb4069954aa771ac0afd8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b54c2335b5584a76a3bbb95fac1a0554":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfec69fa4b33401bba3e6d76d090603b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c1262f5d36540f292b7ad92cfce80a9","IPY_MODEL_076ac09099eb4af989125beff32c53b8","IPY_MODEL_c27de42fcfc840b98406bb178a5e8a79"],"layout":"IPY_MODEL_42f6c4d0d1b24db1a853abb8ab05dda5"}},"2c1262f5d36540f292b7ad92cfce80a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4d4c8acb0c744f2967a3d6522a8cf58","placeholder":"​","style":"IPY_MODEL_fc3705a48dd84784a71a01e970be4bee","value":"Resolving data files: 100%"}},"076ac09099eb4af989125beff32c53b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3dcfd9d78cb4b1880b95d7f31bbea63","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6afcdf0c69fb4699addb1cc17e1e5368","value":30}},"c27de42fcfc840b98406bb178a5e8a79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92015c80b7664610831e5dee99bc38ae","placeholder":"​","style":"IPY_MODEL_fae05f8fafc0436797948604cef8e9fc","value":" 30/30 [00:00&lt;00:00, 21.06it/s]"}},"42f6c4d0d1b24db1a853abb8ab05dda5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4d4c8acb0c744f2967a3d6522a8cf58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc3705a48dd84784a71a01e970be4bee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3dcfd9d78cb4b1880b95d7f31bbea63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6afcdf0c69fb4699addb1cc17e1e5368":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"92015c80b7664610831e5dee99bc38ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fae05f8fafc0436797948604cef8e9fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1926230,"sourceType":"datasetVersion","datasetId":1148896}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iX2IB2DfQBo9","outputId":"1319624c-ac1e-4b7e-c7e6-4842c66e3ba2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AdamW\nfrom datasets import load_dataset\nfrom datasets import Dataset, DatasetDict, load_dataset","metadata":{"id":"1J7qhQMB36hK","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T20:58:15.259604Z","iopub.execute_input":"2024-12-25T20:58:15.259952Z","iopub.status.idle":"2024-12-25T20:58:17.717392Z","shell.execute_reply.started":"2024-12-25T20:58:15.259925Z","shell.execute_reply":"2024-12-25T20:58:17.716742Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load the dataset\ndataset = load_dataset(\"wmt14\", \"fr-en\", split=\"train\", streaming=True)\n\nstreamed_samples = []\nfor i, sample in enumerate(dataset.take(5500)):\n    # Flatten the sample (remove \"translation\" key)\n    streamed_samples.append({\n        \"fr\": sample[\"translation\"][\"fr\"],\n        \"en\": sample[\"translation\"][\"en\"]\n    })\n\n# Convert the list of samples into a Hugging Face Dataset\ntrain_dataset = Dataset.from_dict({\n    \"fr\": [item[\"fr\"] for item in streamed_samples],\n    \"en\": [item[\"en\"] for item in streamed_samples]\n})\n# Load the tokenizer and model for XLM-RoBERTa\nmodel_name = \"facebook/m2m100_418M\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"id":"dEfqnU-d38A6","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T20:58:17.718315Z","iopub.execute_input":"2024-12-25T20:58:17.718642Z","iopub.status.idle":"2024-12-25T20:58:25.137840Z","shell.execute_reply.started":"2024-12-25T20:58:17.718621Z","shell.execute_reply":"2024-12-25T20:58:25.136967Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd65fb69a5b74f68acb6e640e42fa88a"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"M2M100ForConditionalGeneration(\n  (model): M2M100Model(\n    (shared): M2M100ScaledWordEmbedding(128112, 1024, padding_idx=1)\n    (encoder): M2M100Encoder(\n      (embed_tokens): M2M100ScaledWordEmbedding(128112, 1024, padding_idx=1)\n      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-11): 12 x M2M100EncoderLayer(\n          (self_attn): M2M100Attention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): ReLU()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): M2M100Decoder(\n      (embed_tokens): M2M100ScaledWordEmbedding(128112, 1024, padding_idx=1)\n      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-11): 12 x M2M100DecoderLayer(\n          (self_attn): M2M100Attention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): ReLU()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): M2M100Attention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=128112, bias=False)\n)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Define a custom dataset class\nclass TranslationDataset(Dataset):\n    def __init__(self, dataset, tokenizer, max_length=128):\n        self.dataset = dataset\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        data = self.dataset[idx]\n        source_text = data[\"fr\"]\n        target_text = data[\"en\"]\n\n        # Tokenize the source and target texts\n        inputs = self.tokenizer(\n            source_text,\n            max_length=self.max_length,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n        targets = self.tokenizer(\n            target_text,\n            max_length=self.max_length,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n\n        # Return tokenized input and target data\n        return {\n            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n            \"labels\": targets[\"input_ids\"].squeeze(),\n        }\n\n# Prepare the dataset and DataLoader\ntrain_dataset = TranslationDataset(train_dataset, tokenizer)\ntrain_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)","metadata":{"id":"UF3d7HuO4AUc","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T20:58:25.139228Z","iopub.execute_input":"2024-12-25T20:58:25.139642Z","iopub.status.idle":"2024-12-25T20:58:25.145214Z","shell.execute_reply.started":"2024-12-25T20:58:25.139620Z","shell.execute_reply":"2024-12-25T20:58:25.144532Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Define optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\nepochs = 4\nmodel.train()\n\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    epoch_loss = 0\n    batch_count = 0\n    for batch in train_dataloader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels,\n        )\n\n        loss = outputs.loss\n        epoch_loss += loss.item()\n        batch_count += 1\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    avg_epoch_loss = epoch_loss / batch_count\n    print(f\"Epoch {epoch + 1} Average Loss: {avg_epoch_loss:.4f}\\n\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381,"referenced_widgets":["7e7adcb85f194da1b1aa232646e65f6a","ce687ee043144a93ad6ad052417f5174","7f7c3fea5eb04e2ebf73dc4b79f171cb","c47eec9d3a11419c88337a1eb85ba5ec","401be88ff55d4f79b35431f6ca01b616","38526434c5ad4945af165cfe762e5f2f","f590c18cfc6e43be9c2407e2134955d2","23d3ff826a8b4ecc952db67be01a6abf","64ebdadacfcc489e95df535499dd8018","620ffe61b4bb4069954aa771ac0afd8d","b54c2335b5584a76a3bbb95fac1a0554"]},"id":"aMgMPh5cPoCj","outputId":"e5a6212b-afa6-4811-d479-1362a8224150","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T20:58:25.145996Z","iopub.execute_input":"2024-12-25T20:58:25.146277Z","iopub.status.idle":"2024-12-25T21:44:54.075070Z","shell.execute_reply.started":"2024-12-25T20:58:25.146257Z","shell.execute_reply":"2024-12-25T21:44:54.074248Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/4\nEpoch 1 Average Loss: 0.9590\n\nEpoch 2/4\nEpoch 2 Average Loss: 0.3808\n\nEpoch 3/4\nEpoch 3 Average Loss: 0.2983\n\nEpoch 4/4\nEpoch 4 Average Loss: 0.2344\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nexternal_texts = [\n    \"Bonjour, comment ça va ?\",\n    \"J'aime apprendre de nouvelles choses.\",\n    \"La machine traduit ce texte.\",\n    \"C'est un test de traduction automatique.\"\n]\n\nmodel_name = \"facebook/m2m100_418M\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device) \ndef tokenize_function(texts):\n    return tokenizer(\n        texts,   \n        padding=True,\n        truncation=True,\n        max_length=128,\n        return_tensors=\"pt\"\n    )\n\ninputs = tokenize_function(external_texts)\ninput_ids = inputs[\"input_ids\"].to(device)\nattention_mask = inputs[\"attention_mask\"].to(device)\n\nmodel.eval()\nwith torch.no_grad():\n    outputs = model.generate(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n        max_length=128,\n        forced_bos_token_id=tokenizer.lang_code_to_id[\"en\"]\n    )\n\ntranslated_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n\nfor original, translated in zip(external_texts, translated_texts):\n    print(f\"Original (FR): {original}\")\n    print(f\"Translated (EN): {translated}\\n\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tqUioBiBPsKP","outputId":"bd741e17-6b5f-4601-8d78-6a95eb464e4f","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T21:46:37.547721Z","iopub.execute_input":"2024-12-25T21:46:37.548327Z","iopub.status.idle":"2024-12-25T21:46:39.875845Z","shell.execute_reply.started":"2024-12-25T21:46:37.548300Z","shell.execute_reply":"2024-12-25T21:46:39.874966Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Original (FR): Bonjour, comment ça va ?\nTranslated (EN): Hello, how is it?\n\nOriginal (FR): J'aime apprendre de nouvelles choses.\nTranslated (EN): I like to learn new things.\n\nOriginal (FR): La machine traduit ce texte.\nTranslated (EN): The machine translates the text.\n\nOriginal (FR): C'est un test de traduction automatique.\nTranslated (EN): This is an automatic translation test.\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"wmt14\", \"fr-en\", split=\"validation\")\n\ndef translate(text, model, tokenizer, device):\n    model.eval()\n    with torch.no_grad():\n        inputs = tokenizer(\n            text,\n            return_tensors=\"pt\",\n            truncation=True,\n            padding=True,\n            max_length=128\n        ).to(device)\n\n        outputs = model.generate(\n            input_ids=inputs[\"input_ids\"],\n            attention_mask=inputs[\"attention_mask\"],\n            max_length=128,\n            forced_bos_token_id=tokenizer.lang_code_to_id[\"en\"]\n        )\n\n        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\ntest_examples = dataset.select(range(2000, 2500))\n\npredictions = []\nreferences = []\n\nprint(\"Evaluating BLEU score on 10 samples...\")\nfor i, example in enumerate(test_examples):\n    if i >= 10:\n        break\n\n    french_text = example[\"translation\"][\"fr\"]\n    expected_english = example[\"translation\"][\"en\"]\n\n    try:\n        translated_text = translate(french_text, model, tokenizer, device)\n\n        predictions.append(translated_text.split())\n        references.append([expected_english.split()])\n\n        print(f\"French: {french_text}\")\n        print(f\"Expected English: {expected_english}\")\n        print(f\"Model Output: {translated_text}\")\n        print(\"-\" * 50)\n    except Exception as e:\n        print(f\"Error during translation: {e}\")\n\nbleu_score = corpus_bleu(references, predictions)\nprint(f\"\\nBLEU Score: {bleu_score:.4f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":795,"referenced_widgets":["cfec69fa4b33401bba3e6d76d090603b","2c1262f5d36540f292b7ad92cfce80a9","076ac09099eb4af989125beff32c53b8","c27de42fcfc840b98406bb178a5e8a79","42f6c4d0d1b24db1a853abb8ab05dda5","b4d4c8acb0c744f2967a3d6522a8cf58","fc3705a48dd84784a71a01e970be4bee","b3dcfd9d78cb4b1880b95d7f31bbea63","6afcdf0c69fb4699addb1cc17e1e5368","92015c80b7664610831e5dee99bc38ae","fae05f8fafc0436797948604cef8e9fc"]},"id":"TctNQuyjUdVr","outputId":"b2cd097a-a88d-4f36-8267-da0b57d31581","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"jEWrnnbGaBV5","trusted":true},"outputs":[],"execution_count":null}]}